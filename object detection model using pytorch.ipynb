{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os, zipfile, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "print('Imports loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487a3432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility + device\n",
    "SEED = int(os.environ.get('PROJECT_SEED', 42))\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4854d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration (portable): env vars -> ./data -> auto-detect\n",
    "DEMO_MODE = os.environ.get('DEMO_MODE', '1') == '1'  # set to '0' for full runs\n",
    "DATA_DIR = os.environ.get('PROJECT_DATA_DIR', './data')\n",
    "# Allow explicit CSV/ZIP via env vars (overrides auto-detect)\n",
    "TRAIN_CSV_PATH = os.environ.get('TRAIN_CSV_PATH')\n",
    "TEST_CSV_PATH = os.environ.get('TEST_CSV_PATH')\n",
    "ZIP_FILE_PATH = os.environ.get('ZIP_FILE_PATH')\n",
    "EXTRACT_DIR = os.environ.get('EXTRACT_DIR', os.path.join(DATA_DIR, 'images'))\n",
    "CONFIG = {\n",
    "    'batch_size': 8 if not DEMO_MODE else 4,\n",
    "    'num_workers': 0,\n",
    "    'epochs': 3 if DEMO_MODE else 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_classes': 61,\n",
    "    'image_size': 224,\n",
    "    'bbox_loss_weight': 0.01\n",
    "}\n",
    "print('CONFIG loaded, DEMO_MODE=', DEMO_MODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5db64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: extract zip and find csvs/images\n",
    "def extract_zip_dataset(zip_path, extract_to='./data'):\n",
    "    extract_path = Path(extract_to)\n",
    "    extract_path.mkdir(parents=True, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(extract_path)\n",
    "    return extract_path\n",
    "\n",
    "def find_csv_and_images(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    csvs = list(root.rglob('*.csv'))\n",
    "    train_csv = None\n",
    "    test_csv = None\n",
    "    for c in csvs:\n",
    "        name = c.name.lower()\n",
    "        if 'train' in name and train_csv is None:\n",
    "            train_csv = str(c)\n",
    "        if 'test' in name and test_csv is None:\n",
    "            test_csv = str(c)\n",
    "    # images dir: choose a folder containing many jpg/png files\n",
    "    image_dir = None\n",
    "    for d in root.rglob('*'):\n",
    "        try:\n",
    "            if d.is_dir() and any(f.suffix.lower() in ['.jpg', '.jpeg', '.png'] for f in d.iterdir()):\n",
    "                image_dir = str(d)\n",
    "                break\n",
    "        except Exception:\n",
    "            pass\n",
    "    if image_dir is None:\n",
    "        image_dir = str(root)\n",
    "    return dict(train_csv=train_csv, test_csv=test_csv, image_dir=image_dir)\n",
    "\n",
    "print('Helper functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class (same API as original but portable)\n",
    "class CowStallDataset(Dataset):\n",
    "    def __init__(self, df, image_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        fname = str(row[0])\n",
    "        img_path = os.path.join(self.image_dir, fname)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f'Image not found: {img_path}')\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (CONFIG['image_size'], CONFIG['image_size']))\n",
    "        img = img.astype('float32') / 255.0\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = torch.tensor(int(row[5]), dtype=torch.long)\n",
    "        bbox = row[['box_position_1','box_position_2','box_position_3','box_position_4']].values.astype('float32')\n",
    "        bbox[2] = bbox[0] + bbox[2]\n",
    "        bbox[3] = bbox[1] + bbox[3]\n",
    "        bbox = torch.as_tensor(bbox, dtype=torch.float32)\n",
    "        return img, label, bbox\n",
    "\n",
    "print('Dataset class defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms (accept numpy arrays as input)\n",
    "IMAGE_SIZE = CONFIG['image_size']\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "print('Transforms prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4efdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: prefer env paths, then ./data, then auto-detect inside zip if provided\n",
    "print('\n",
    "--- Loading dataset (portable) ---')\n",
    "# Ensure data dir exists\n",
    "Path(DATA_DIR).mkdir(parents=True, exist_ok=True)\n",
    "# If explicit CSV env vars were not set, look inside ./data or inside ZIP\n",
    "if not TRAIN_CSV_PATH or not TEST_CSV_PATH:\n",
    "    # try common filenames in DATA_DIR\n",
    "    for name in ['train.csv','Train.csv']:\n",
    "        candidate = os.path.join(DATA_DIR, name)\n",
    "        if os.path.exists(candidate):\n",
    "            TRAIN_CSV_PATH = TRAIN_CSV_PATH or candidate\n",
    "            break\n",
    "    for name in ['test.csv','Test.csv']:\n",
    "        candidate = os.path.join(DATA_DIR, name)\n",
    "        if os.path.exists(candidate):\n",
    "            TEST_CSV_PATH = TEST_CSV_PATH or candidate\n",
    "            break\n",
    "# If ZIP provided and CSVs still not found, extract and search\n",
    "if (not TRAIN_CSV_PATH or not TEST_CSV_PATH) and ZIP_FILE_PATH and os.path.exists(ZIP_FILE_PATH):\n",
    "    print('Extracting ZIP to', EXTRACT_DIR)\n",
    "    extracted = extract_zip_dataset(ZIP_FILE_PATH, EXTRACT_DIR)\n",
    "    info = find_csv_and_images(extracted)\n",
    "    TRAIN_CSV_PATH = TRAIN_CSV_PATH or info.get('train_csv')\n",
    "    TEST_CSV_PATH = TEST_CSV_PATH or info.get('test_csv')\n",
    "    IMAGE_DIR = IMAGE_DIR or info.get('image_dir')\n",
    "\n",
    "# If still missing, try searching workspace root as last resort\n",
    "if (not TRAIN_CSV_PATH or not TEST_CSV_PATH):\n",
    "    root_info = find_csv_and_images('.')\n",
    "    TRAIN_CSV_PATH = TRAIN_CSV_PATH or root_info.get('train_csv')\n",
    "    TEST_CSV_PATH = TEST_CSV_PATH or root_info.get('test_csv')\n",
    "    IMAGE_DIR = IMAGE_DIR or root_info.get('image_dir')\n",
    "\n",
    "# If IMAGE_DIR still None, fall back to EXTRACT_DIR or DATA_DIR\n",
    "if IMAGE_DIR is None:\n",
    "    if os.path.exists(EXTRACT_DIR):\n",
    "        IMAGE_DIR = EXTRACT_DIR\n",
    "    elif os.path.exists(DATA_DIR):\n",
    "        IMAGE_DIR = DATA_DIR\n",
    "\n",
    "print('Resolved paths:')\n",
    "print('  TRAIN_CSV_PATH =', TRAIN_CSV_PATH)\n",
    "print('  TEST_CSV_PATH  =', TEST_CSV_PATH)\n",
    "print('  IMAGE_DIR      =', IMAGE_DIR)\n",
    "\n",
    "# Final existence checks and load\n",
    "if not TRAIN_CSV_PATH or not TEST_CSV_PATH or not IMAGE_DIR:\n",
    "    raise FileNotFoundError('Train/Test CSV or image dir not found. Place files into ./data or set environment variables.')\n",
    "\n",
    "df_train = pd.read_csv(TRAIN_CSV_PATH).fillna(0)\n",
    "df_test = pd.read_csv(TEST_CSV_PATH).fillna(0)\n",
    "print('Loaded dataframes: train=', len(df_train), ' test=', len(df_test))\n",
    "# DEMO: if DEMO_MODE, sample small subset to speed up runs\n",
    "if DEMO_MODE:\n",
    "    df_train = df_train.sample(n=min(32, len(df_train)), random_state=SEED).reset_index(drop=True)\n",
    "    df_test = df_test.sample(n=min(16, len(df_test)), random_state=SEED).reset_index(drop=True)\n",
    "    print('DEMO_MODE: sampled train=', len(df_train), ' test=', len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3aae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = CowStallDataset(df_train, IMAGE_DIR, transform=train_transform)\n",
    "test_dataset = CowStallDataset(df_test, IMAGE_DIR, transform=test_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, num_workers=CONFIG['num_workers'])\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, num_workers=CONFIG['num_workers'])\n",
    "print('DataLoaders:', len(train_loader), 'train batches,', len(test_loader), 'test batches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model (ResNet50 backbone with two heads)\n",
    "class ObjectDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes=61, num_bbox=4):\n",
    "        super().__init__()\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        nf = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.classifier = nn.Linear(nf, num_classes)\n",
    "        self.bbox_regressor = nn.Linear(nf, num_bbox)\n",
    "    def forward(self, x):\n",
    "        feats = self.backbone(x)\n",
    "        logits = self.classifier(feats)\n",
    "        bbox = self.bbox_regressor(feats)\n",
    "        return logits, bbox\n",
    "\n",
    "model = ObjectDetectionModel(num_classes=CONFIG['num_classes']).to(device)\n",
    "print('Model ready, params:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da32f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "criterion_cls = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.MSELoss()\n",
    "optimizer = optim.Adam([p for p in model.parameters() if p.requires_grad], lr=CONFIG['learning_rate'], weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "EPOCHS = CONFIG['epochs']\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels, bboxes in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        bboxes = bboxes.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, bbox_preds = model(images)\n",
    "        loss1 = criterion_cls(logits, labels)\n",
    "        loss2 = torch.sqrt(criterion_bbox(bbox_preds, bboxes)) * CONFIG['bbox_loss_weight']\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} - loss: {running_loss/len(train_loader):.4f}')\n",
    "    if DEMO_MODE and epoch==0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a small checkpoint\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "torch.save({'model_state_dict': model.state_dict(), 'config': CONFIG}, './models/portable_checkpoint.pt')\n",
    "print('Saved checkpoint to ./models/portable_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f977ec6",
   "metadata": {},
   "source": [
    "---\n",
    "Notes:\n",
    "- For full training, set `DEMO_MODE=0` and adjust `CONFIG['epochs']`.\n",
    "- To run on another machine, set `PROJECT_DATA_DIR` or `TRAIN_CSV_PATH`/`TEST_CSV_PATH` env vars.\n",
    "- See `README.md` in the project root for instructions on dataset placement and recommended Git LFS usage."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
