{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15e035ba",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36bbcfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0df723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d17eed",
   "metadata": {},
   "source": [
    "## 2. Dataset Handling (Local .zip or Direct Paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3d464ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset handling functions defined.\n"
     ]
    }
   ],
   "source": [
    "def extract_zip_dataset(zip_path, extract_to=\"./dataset\"):\n",
    "    \"\"\"\n",
    "    Extract dataset from zip file.\n",
    "    \n",
    "    Args:\n",
    "        zip_path: Path to the .zip file\n",
    "        extract_to: Directory to extract to\n",
    "    \n",
    "    Returns:\n",
    "        Path to extracted dataset directory\n",
    "    \"\"\"\n",
    "    extract_path = Path(extract_to)\n",
    "    extract_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        print(f\"Extracting {zip_path}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        print(f\"‚úì Dataset extracted successfully\")\n",
    "        return extract_path\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚úó Zip file not found: {zip_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error extracting zip file: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def find_csv_and_images(dataset_dir):\n",
    "    \"\"\"\n",
    "    Find CSV files and image directory in extracted dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_dir: Root directory of dataset\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with paths to CSVs and image directory\n",
    "    \"\"\"\n",
    "    dataset_path = Path(dataset_dir)\n",
    "    \n",
    "    # Find CSV files\n",
    "    csv_files = list(dataset_path.rglob('*.csv'))\n",
    "    train_csv = None\n",
    "    test_csv = None\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        if 'train' in csv_file.name.lower():\n",
    "            train_csv = csv_file\n",
    "        elif 'test' in csv_file.name.lower():\n",
    "            test_csv = csv_file\n",
    "    \n",
    "    # Find image directories\n",
    "    image_dirs = []\n",
    "    for item in dataset_path.rglob('*'):\n",
    "        if item.is_dir() and any(item.glob('*.jpg')) or any(item.glob('*.png')):\n",
    "            image_dirs.append(item)\n",
    "    \n",
    "    # Use the most common image directory\n",
    "    image_dir = image_dirs[0] if image_dirs else dataset_path\n",
    "    \n",
    "    return {\n",
    "        'train_csv': train_csv,\n",
    "        'test_csv': test_csv,\n",
    "        'image_dir': image_dir\n",
    "    }\n",
    "\n",
    "print(\"Dataset handling functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f22a15",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (ipython-input-781616363.py, line 88)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-781616363.py\"\u001b[0;36m, line \u001b[0;32m88\u001b[0m\n\u001b[0;31m    print(f\"Explicit override - TEST_CSV_PATH  = {TEST_CSV_PATH}\")print(f\"Explicit override - TRAIN_CSV_PATH = {TRAIN_CSV_PATH}\")TEST_CSV_PATH = TEST_CSV_PATH or '/Users/jainam/Downloads/Neural Network/bject Detection Model using PyTorch/test.csv'TRAIN_CSV_PATH = TRAIN_CSV_PATH or '/Users/jainam/Downloads/Neural Network/bject Detection Model using PyTorch/train.csv'# which will override any earlier auto-detection. Change these if needed.# We'll set explicit absolute paths for both train and test CSVs (lowercase),# NOTE: you told me your test CSV path is: /Users/jainam/Downloads/Neural Network/bject Detection Model using PyTorch/test.csv# ------------------------------------------------------------------# Update these if your CSVs are in a non-standard location.\u001b[0m\n\u001b[0m                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - CHOOSE ONE OPTION BELOW\n",
    "# ============================================================================\n",
    "\n",
    "# OPTION 1: Images in ZIP, CSVs in current directory (RECOMMENDED FOR YOUR SETUP)\n",
    "USE_HYBRID_MODE = True\n",
    "ZIP_FILE_PATH = './Stall_num_images.zip'  # Images are here (change if different)\n",
    "EXTRACT_DIR = './images'                   # Extract images to this folder\n",
    "\n",
    "# OPTION 2: Auto-detect local CSV files and images in same directory\n",
    "USE_AUTO_DETECT = False\n",
    "\n",
    "# OPTION 3: Using .zip file (everything in zip)\n",
    "USE_ZIP = False\n",
    "EXTRACT_DIR_ZIP = './dataset'\n",
    "\n",
    "# OPTION 4: Using local paths directly\n",
    "# USE_AUTO_DETECT = False\n",
    "# USE_ZIP = False\n",
    "# USE_HYBRID_MODE = False\n",
    "# IMAGE_DIR = './Stall_num_images'\n",
    "# TRAIN_CSV_PATH = './Train.csv'\n",
    "# TEST_CSV_PATH = './Test.csv'\n",
    "\n",
    "# ============================================================================\n",
    "# Common Configuration\n",
    "# ============================================================================\n",
    "CONFIG = {\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 0,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 0.0001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'num_classes': 61,\n",
    "    'image_size': 224,\n",
    "    'bbox_loss_weight': 0.01\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Explicit user paths (override auto-detection)\n",
    "# Set absolute paths for your CSVs so the notebook finds them reliably.\n",
    "# Update these if your files are elsewhere.\n",
    "# ------------------------------------------------------------------\n",
    "TRAIN_CSV_PATH = '/Users/jainam/Downloads/Neural Network/bject Detection Model using PyTorch/train.csv'\n",
    "TEST_CSV_PATH = '/Users/jainam/Downloads/Neural Network/bject Detection Model using PyTorch/test.csv'\n",
    "IMAGE_DIR = None\n",
    "\n",
    "# Auto-detect a ZIP file for hybrid mode if ZIP_FILE_PATH doesn't exist\n",
    "cwd = os.getcwd()\n",
    "if USE_HYBRID_MODE and (not ZIP_FILE_PATH or not os.path.exists(ZIP_FILE_PATH)):\n",
    "    zip_candidates = [f for f in os.listdir(cwd) if f.lower().endswith('.zip')]\n",
    "    if zip_candidates:\n",
    "        ZIP_FILE_PATH = os.path.join(cwd, zip_candidates[0])\n",
    "        print(f\"Auto-detected ZIP file for hybrid mode: {ZIP_FILE_PATH}\")\n",
    "\n",
    "print(\"Configuration loaded.\")\n",
    "print(f\"Mode flags - USE_HYBRID_MODE={USE_HYBRID_MODE}, USE_AUTO_DETECT={USE_AUTO_DETECT}, USE_ZIP={USE_ZIP}\")\n",
    "print(f\"TRAIN_CSV_PATH={TRAIN_CSV_PATH}\")\n",
    "print(f\"TEST_CSV_PATH={TEST_CSV_PATH}\")\n",
    "print(f\"ZIP_FILE_PATH={ZIP_FILE_PATH}\")\n",
    "print(f\"EXTRACT_DIR={EXTRACT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d33747ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Hybrid Mode: Extracting images from ZIP, finding CSVs in current directory...\n",
      "\n",
      "üìÑ Step 1: Looking for CSV files in current directory...\n",
      "  ‚úó CSV files not found in current directory\n",
      "    Found training CSVs: []\n",
      "    Found test CSVs: []\n",
      "\n",
      "üì¶ Step 2: Extracting images from ZIP file...\n",
      "  ‚úó ZIP file not found: ./Stall_num_images.zip\n",
      "\n",
      "Available files in current directory (/content):\n",
      "  - .config\n",
      "  - sample_data\n",
      "\n",
      "‚úì Verifying paths...\n",
      "  ‚ùå Paths not configured properly\n",
      "  TRAIN_CSV_PATH: None\n",
      "  TEST_CSV_PATH: None\n",
      "  IMAGE_DIR: None\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# HYBRID MODE: Images from ZIP, CSVs from current directory\n",
    "# ============================================================================\n",
    "if USE_HYBRID_MODE:\n",
    "    print(\"\\nüîÑ Hybrid Mode: Extracting images from ZIP, finding CSVs in current directory...\\n\")\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    # Step 1: Find CSV files in current directory\n",
    "    print(\"üìÑ Step 1: Looking for CSV files in current directory...\")\n",
    "    train_csv_candidates = [f for f in os.listdir(current_dir) if 'train' in f.lower() and f.endswith('.csv')]\n",
    "    test_csv_candidates = [f for f in os.listdir(current_dir) if 'test' in f.lower() and f.endswith('.csv')]\n",
    "    \n",
    "    if train_csv_candidates and test_csv_candidates:\n",
    "        TRAIN_CSV_PATH = os.path.join(current_dir, train_csv_candidates[0])\n",
    "        TEST_CSV_PATH = os.path.join(current_dir, test_csv_candidates[0])\n",
    "        print(f\"  ‚úì Found Training CSV: {train_csv_candidates[0]}\")\n",
    "        print(f\"  ‚úì Found Test CSV: {test_csv_candidates[0]}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó CSV files not found in current directory\")\n",
    "        print(f\"    Found training CSVs: {train_csv_candidates}\")\n",
    "        print(f\"    Found test CSVs: {test_csv_candidates}\")\n",
    "    \n",
    "    # Step 2: Extract images from ZIP file\n",
    "    print(f\"\\nüì¶ Step 2: Extracting images from ZIP file...\")\n",
    "    if os.path.exists(ZIP_FILE_PATH):\n",
    "        try:\n",
    "            dataset_dir = extract_zip_dataset(ZIP_FILE_PATH, EXTRACT_DIR)\n",
    "            IMAGE_DIR = str(dataset_dir)\n",
    "            print(f\"  ‚úì Images extracted to: {IMAGE_DIR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚úó Error extracting ZIP: {e}\")\n",
    "            IMAGE_DIR = None\n",
    "    else:\n",
    "        print(f\"  ‚úó ZIP file not found: {ZIP_FILE_PATH}\")\n",
    "        print(f\"\\nAvailable files in current directory ({current_dir}):\")\n",
    "        for item in os.listdir(current_dir)[:20]:\n",
    "            print(f\"  - {item}\")\n",
    "\n",
    "# ============================================================================\n",
    "# AUTO-DETECT MODE: Find both CSVs and images in current directory\n",
    "# ============================================================================\n",
    "elif USE_AUTO_DETECT:\n",
    "    print(\"\\nüîç Auto-detect Mode: Searching for CSV files and images...\\n\")\n",
    "    current_dir = os.getcwd()\n",
    "    print(f\"Current directory: {current_dir}\\n\")\n",
    "    \n",
    "    train_csv_candidates = [f for f in os.listdir(current_dir) if 'train' in f.lower() and f.endswith('.csv')]\n",
    "    test_csv_candidates = [f for f in os.listdir(current_dir) if 'test' in f.lower() and f.endswith('.csv')]\n",
    "    \n",
    "    if train_csv_candidates and test_csv_candidates:\n",
    "        TRAIN_CSV_PATH = os.path.join(current_dir, train_csv_candidates[0])\n",
    "        TEST_CSV_PATH = os.path.join(current_dir, test_csv_candidates[0])\n",
    "        \n",
    "        # Look for image directory\n",
    "        IMAGE_DIR = None\n",
    "        for item in os.listdir(current_dir):\n",
    "            item_path = os.path.join(current_dir, item)\n",
    "            if os.path.isdir(item_path) and item.lower() not in ['__pycache__', '.config', 'sample_data', '.git']:\n",
    "                try:\n",
    "                    if any(f.lower().endswith(('.jpg', '.png', '.jpeg')) for f in os.listdir(item_path)):\n",
    "                        IMAGE_DIR = os.path.abspath(item_path)\n",
    "                        break\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        # If no image dir found, assume images are in current directory\n",
    "        if IMAGE_DIR is None:\n",
    "            IMAGE_DIR = current_dir\n",
    "        \n",
    "        print(f\"‚úì Auto-detected paths:\")\n",
    "        print(f\"  Train CSV: {TRAIN_CSV_PATH}\")\n",
    "        print(f\"  Test CSV: {TEST_CSV_PATH}\")\n",
    "        print(f\"  Image directory: {IMAGE_DIR}\")\n",
    "    else:\n",
    "        print(f\"‚úó Could not auto-detect CSVs\")\n",
    "        print(f\"  Found training CSVs: {train_csv_candidates}\")\n",
    "        print(f\"  Found test CSVs: {test_csv_candidates}\")\n",
    "        print(f\"\\nüìù Please set USE_HYBRID_MODE=True or manually configure paths\")\n",
    "\n",
    "# ============================================================================\n",
    "# ZIP MODE: Everything in ZIP file\n",
    "# ============================================================================\n",
    "elif USE_ZIP:\n",
    "    print(f\"\\nüì¶ ZIP Mode: Attempting to extract ZIP file...\\n\")\n",
    "    if not os.path.exists(ZIP_FILE_PATH):\n",
    "        print(f\"‚úó Error: {ZIP_FILE_PATH} not found!\")\n",
    "        print(f\"\\nCurrent working directory: {os.getcwd()}\")\n",
    "        print(f\"\\nFiles in current directory:\")\n",
    "        for item in os.listdir(os.getcwd())[:20]:  # Show first 20 items\n",
    "            print(f\"  - {item}\")\n",
    "        print(f\"\\n‚ö†Ô∏è  Please upload the ZIP file or set USE_HYBRID_MODE=True\")\n",
    "    else:\n",
    "        dataset_dir = extract_zip_dataset(ZIP_FILE_PATH, EXTRACT_DIR_ZIP)\n",
    "        paths_info = find_csv_and_images(dataset_dir)\n",
    "        \n",
    "        IMAGE_DIR = str(paths_info['image_dir'])\n",
    "        TRAIN_CSV_PATH = str(paths_info['train_csv'])\n",
    "        TEST_CSV_PATH = str(paths_info['test_csv'])\n",
    "        \n",
    "        print(f\"‚úì Dataset paths found:\")\n",
    "        print(f\"  Image directory: {IMAGE_DIR}\")\n",
    "        print(f\"  Train CSV: {TRAIN_CSV_PATH}\")\n",
    "        print(f\"  Test CSV: {TEST_CSV_PATH}\")\n",
    "\n",
    "# ============================================================================\n",
    "# VERIFY PATHS\n",
    "# ============================================================================\n",
    "print(f\"\\n‚úì Verifying paths...\")\n",
    "if TRAIN_CSV_PATH and TEST_CSV_PATH and IMAGE_DIR:\n",
    "    train_exists = os.path.exists(TRAIN_CSV_PATH)\n",
    "    test_exists = os.path.exists(TEST_CSV_PATH)\n",
    "    image_exists = os.path.exists(IMAGE_DIR)\n",
    "    \n",
    "    print(f\"  Train CSV exists: {train_exists}\")\n",
    "    print(f\"  Test CSV exists: {test_exists}\")\n",
    "    print(f\"  Image directory exists: {image_exists}\")\n",
    "    \n",
    "    if train_exists and test_exists and image_exists:\n",
    "        print(f\"\\n‚úì All paths verified! Ready to load data.\")\n",
    "    else:\n",
    "        print(f\"\\n‚ö†Ô∏è  Some paths are missing. Please check configuration.\")\n",
    "else:\n",
    "    print(f\"  ‚ùå Paths not configured properly\")\n",
    "    print(f\"  TRAIN_CSV_PATH: {TRAIN_CSV_PATH}\")\n",
    "    print(f\"  TEST_CSV_PATH: {TEST_CSV_PATH}\")\n",
    "    print(f\"  IMAGE_DIR: {IMAGE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53cff85",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a1a8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforms configured for image size: 224x224\n"
     ]
    }
   ],
   "source": [
    "# Define image transforms\n",
    "# ImageNet normalization statistics\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "IMAGE_SIZE = CONFIG['image_size']\n",
    "\n",
    "# Training transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Test transforms (no augmentation for evaluation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "print(f\"Transforms configured for image size: {IMAGE_SIZE}x{IMAGE_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8dea02",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a20c416b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture defined.\n"
     ]
    }
   ],
   "source": [
    "class ObjectDetectionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-task learning model for object detection.\n",
    "    \n",
    "    Architecture:\n",
    "    - Backbone: ResNet50 (pretrained on ImageNet)\n",
    "    - Classification Head: Predicts cow stall numbers (61 classes)\n",
    "    - Regression Head: Predicts bounding box coordinates (4 values)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=61, num_bbox_coords=4):\n",
    "        super(ObjectDetectionModel, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Get the number of input features for the FC layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace FC layer with identity to get feature maps\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Bounding box regression head\n",
    "        self.bbox_regressor = nn.Linear(num_features, num_bbox_coords)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from backbone\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Flatten features\n",
    "        features = self.flatten(features)\n",
    "        \n",
    "        # Classification and bounding box predictions\n",
    "        class_logits = self.classifier(features)\n",
    "        bbox_coords = self.bbox_regressor(features)\n",
    "        \n",
    "        return class_logits, bbox_coords\n",
    "\n",
    "print(\"Model architecture defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f422d9",
   "metadata": {},
   "source": [
    "## 5. Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e484a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom dataset class defined.\n"
     ]
    }
   ],
   "source": [
    "class CowStallDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for cow stall detection.\n",
    "    \n",
    "    Loads images and their corresponding:\n",
    "    - Stall number labels\n",
    "    - Bounding box coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: Pandas DataFrame with image paths and annotations\n",
    "            image_dir: Directory containing images\n",
    "            transform: Torchvision transforms to apply\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Read image\n",
    "            image_filename = self.dataframe.iloc[idx, 0]\n",
    "            image_path = os.path.join(self.image_dir, image_filename)\n",
    "            \n",
    "            image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "            \n",
    "            # Resize image\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "            \n",
    "            # Normalize to [0, 1]\n",
    "            image /= 255.0\n",
    "            \n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            # Get label (stall number)\n",
    "            label = torch.tensor(int(self.dataframe.iloc[idx, 5]), dtype=torch.long)\n",
    "            \n",
    "            # Get bounding box coordinates\n",
    "            bbox_columns = ['box_position_1', 'box_position_2', 'box_position_3', 'box_position_4']\n",
    "            bbox = self.dataframe.loc[idx, bbox_columns].values.astype(np.float32)\n",
    "            \n",
    "            # Convert (x, y, width, height) to (x1, y1, x2, y2)\n",
    "            bbox[2] = bbox[0] + bbox[2]  # x2 = x1 + width\n",
    "            bbox[3] = bbox[1] + bbox[3]  # y2 = y1 + height\n",
    "            \n",
    "            bbox = torch.as_tensor(bbox, dtype=torch.float32)\n",
    "            \n",
    "            return image, label, bbox\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "print(\"Custom dataset class defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575d3e1",
   "metadata": {},
   "source": [
    "## 6. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "053ff0f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (ipython-input-3493565714.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3493565714.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    print('\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data (safe checks + helpful diagnostics)\n",
    "print('\n",
    "print(f'  TRAIN_CSV_PATH = {TRAIN_CSV_PATH}')\n",
    "print(f'  TEST_CSV_PATH  = {TEST_CSV_PATH}')\n",
    "print(f'  ZIP_FILE_PATH  = {ZIP_FILE_PATH if 'ZIP_FILE_PATH' in globals() else None}')\n",
    "print(f'  IMAGE_DIR      = {IMAGE_DIR}')\n",
    "\n",
    "# Fallback: try common filenames in cwd if CSV paths are not set\n",
    "cwd = os.getcwd()\n",
    "if TRAIN_CSV_PATH is None:\n",
    "    for name in ['Train.csv', 'train.csv']:\n",
    "        if os.path.exists(os.path.join(cwd, name)):\n",
    "            TRAIN_CSV_PATH = os.path.join(cwd, name)\n",
    "            print(f'  -> Auto-set TRAIN_CSV_PATH to: {TRAIN_CSV_PATH}')\n",
    "            break\n",
    "\n",
    "if TEST_CSV_PATH is None:\n",
    "    for name in ['Test.csv', 'test.csv']:\n",
    "        if os.path.exists(os.path.join(cwd, name)):\n",
    "            TEST_CSV_PATH = os.path.join(cwd, name)\n",
    "            print(f'  -> Auto-set TEST_CSV_PATH to: {TEST_CSV_PATH}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print(f'‚ùå Error loading data: {e}')    except Exception as e:        print(f'‚ùå Error: CSV file is empty or malformed: {e}')    except pd.errors.EmptyDataError as e:        print(f'‚ùå Error: Could not load CSV files: {e}')    except FileNotFoundError as e:        print(f'\\n  DataFrame columns: {df_train.columns.tolist()}')        print(f'  Test samples: {len(df_test)}')        print(f'  Training samples: {len(df_train)}')        print(f'\\n‚úì Data loaded successfully:')        df_test = pd.read_csv(TEST_CSV_PATH).fillna(0)        df_train = pd.read_csv(TRAIN_CSV_PATH).fillna(0)    try:    print('\n",
    "Loading datasets...')else:    print('  - If images are in a ZIP, ensure ZIP_FILE_PATH points to it and re-run the hybrid extraction cell')    print('  - Update the CONFIG cell to set TRAIN_CSV_PATH, TEST_CSV_PATH, or IMAGE_DIR')    print('  - Place Train.csv and Test.csv into the notebook working directory')    print('Please check one of the following:')    print('\n",
    "‚ùå ERROR: Paths are still not configured or files missing.')if not (train_exists and test_exists and image_exists):print(f'  Image dir exists: {bool(image_exists)}')print(f'  Test CSV exists:  {bool(test_exists)}')print(f'  Train CSV exists: {bool(train_exists)}')image_exists = IMAGE_DIR and os.path.exists(IMAGE_DIR)test_exists = TEST_CSV_PATH and os.path.exists(TEST_CSV_PATH)train_exists = TRAIN_CSV_PATH and os.path.exists(TRAIN_CSV_PATH)print('\n",
    "--- Verifying file existence ---')# Final verification before attempting to load        print(f'  -> Auto-set IMAGE_DIR to ./images: {IMAGE_DIR}')        IMAGE_DIR = os.path.abspath(os.path.join(cwd, 'images'))    elif os.path.exists(os.path.join(cwd, 'images')):        print(f'  -> Auto-set IMAGE_DIR to EXTRACT_DIR: {IMAGE_DIR}')        IMAGE_DIR = os.path.abspath(EXTRACT_DIR)    if os.path.exists(EXTRACT_DIR):if IMAGE_DIR is None:# If IMAGE_DIR not set but extraction dir exists, use that as fallback            break        print(f\"‚ùå Error loading data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afbf6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå Cannot create datasets - paths not configured\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "if TRAIN_CSV_PATH and TEST_CSV_PATH and IMAGE_DIR:\n",
    "    try:\n",
    "        train_dataset = CowStallDataset(\n",
    "            df_train,\n",
    "            IMAGE_DIR,\n",
    "            transform=train_transform\n",
    "        )\n",
    "\n",
    "        test_dataset = CowStallDataset(\n",
    "            df_test,\n",
    "            IMAGE_DIR,\n",
    "            transform=test_transform\n",
    "        )\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=CONFIG['batch_size'],\n",
    "            shuffle=True,\n",
    "            num_workers=CONFIG['num_workers'],\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        test_loader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=CONFIG['batch_size'],\n",
    "            shuffle=False,\n",
    "            num_workers=CONFIG['num_workers'],\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        print(f\"\\n‚úì DataLoaders created:\")\n",
    "        print(f\"  Training batches: {len(train_loader)}\")\n",
    "        print(f\"  Test batches: {len(test_loader)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error creating datasets: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot create datasets - paths not configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed86442",
   "metadata": {},
   "source": [
    "## 7. Model Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794a8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 163MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model moved to cpu\n",
      "Total parameters: 23,641,217\n",
      "Trainable parameters: 23,641,217\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "model = ObjectDetectionModel(\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    num_bbox_coords=4\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model moved to {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f39237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Optimizer: Adam\n",
      "‚úì Scheduler: StepLR (step_size=30, gamma=0.1)\n",
      "‚úì Loss functions: CrossEntropyLoss + MSELoss\n"
     ]
    }
   ],
   "source": [
    "# Loss functions\n",
    "criterion_classification = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(\n",
    "    trainable_params,\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=30,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "print(f\"‚úì Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"‚úì Scheduler: StepLR (step_size=30, gamma=0.1)\")\n",
    "print(f\"‚úì Loss functions: CrossEntropyLoss + MSELoss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afaa1c4a",
   "metadata": {},
   "source": [
    "## 8. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a8206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 100 epochs...\n",
      "\n",
      "Epoch    Train Loss   Train Acc    Val Loss     Val Acc     \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "# Hyperparameters\n",
    "BBOX_LOSS_WEIGHT = CONFIG['bbox_loss_weight']\n",
    "EPOCHS = CONFIG['epochs']\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\\n\")\n",
    "print(f\"{'Epoch':<8} {'Train Loss':<12} {'Train Acc':<12} {'Val Loss':<12} {'Val Acc':<12}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b2a3a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-44348654.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtrain_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbboxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Move data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # ==================== Training ====================\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels, bboxes) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        bboxes = bboxes.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        class_logits, bbox_predictions = model(images)\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_cls = criterion_classification(class_logits, labels)\n",
    "        loss_bbox = torch.sqrt(criterion_bbox(bbox_predictions, bboxes)) * BBOX_LOSS_WEIGHT\n",
    "        loss_total = loss_cls + loss_bbox\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss += loss_total.item()\n",
    "        predictions = torch.argmax(class_logits, dim=1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_accuracy'].append(train_accuracy)\n",
    "    \n",
    "    # ==================== Validation ====================\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, bboxes in test_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            bboxes = bboxes.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            class_logits, bbox_predictions = model(images)\n",
    "            \n",
    "            # Calculate losses\n",
    "            loss_cls = criterion_classification(class_logits, labels)\n",
    "            loss_bbox = torch.sqrt(criterion_bbox(bbox_predictions, bboxes)) * BBOX_LOSS_WEIGHT\n",
    "            loss_total = loss_cls + loss_bbox\n",
    "            \n",
    "            # Update metrics\n",
    "            val_loss += loss_total.item()\n",
    "            predictions = torch.argmax(class_logits, dim=1)\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_loss /= len(test_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_accuracy)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print progress every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"{epoch + 1:<8} {train_loss:<12.4f} {train_accuracy*100:<12.2f} {val_loss:<12.4f} {val_accuracy*100:<12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì TRAINING COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Final Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final Training Accuracy: {history['train_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"Final Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history['val_accuracy'][-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2467d752",
   "metadata": {},
   "source": [
    "## 9. Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2526cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['train_accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best validation accuracy\n",
    "best_epoch = np.argmax(history['val_accuracy']) + 1\n",
    "best_val_acc = np.max(history['val_accuracy'])\n",
    "\n",
    "print(f\"\\nBest Validation Accuracy: {best_val_acc*100:.2f}% (Epoch {best_epoch})\")\n",
    "if best_val_acc > 0.8:\n",
    "    print(f\"‚úì Model exceeds 80% accuracy requirement\")\n",
    "else:\n",
    "    print(f\"‚úó Below 80% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f57bb1",
   "metadata": {},
   "source": [
    "## 10. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead81721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('./models', exist_ok=True)\n",
    "\n",
    "# Save model checkpoint\n",
    "model_save_path = './models/object_detection_model.pt'\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'train_loss': history['train_loss'][-1],\n",
    "    'val_loss': history['val_loss'][-1],\n",
    "    'val_accuracy': history['val_accuracy'][-1],\n",
    "    'config': CONFIG,\n",
    "    'history': history\n",
    "}\n",
    "\n",
    "try:\n",
    "    torch.save(checkpoint, model_save_path)\n",
    "    print(f\"‚úì Model saved successfully to: {model_save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Error saving model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb6b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model function for future use\n",
    "def load_model(checkpoint_path, device):\n",
    "    \"\"\"\n",
    "    Load model from checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to saved checkpoint\n",
    "        device: Device to load model on\n",
    "    \n",
    "    Returns:\n",
    "        Loaded model and checkpoint information\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model = ObjectDetectionModel(\n",
    "        num_classes=checkpoint['config']['num_classes'],\n",
    "        num_bbox_coords=4\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "print(\"Model loading function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3588ff83",
   "metadata": {},
   "source": [
    "## 11. Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0200d8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Dataset: Cow Stall Number Detection\")\n",
    "print(f\"   Training samples: {len(df_train)}\")\n",
    "print(f\"   Test samples: {len(df_test)}\")\n",
    "print(f\"\\nüîß Model Architecture: ObjectDetectionModel\")\n",
    "print(f\"   Backbone: ResNet50 (pretrained)\")\n",
    "print(f\"   Classification classes: {CONFIG['num_classes']}\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"\\n‚öôÔ∏è  Training Configuration:\")\n",
    "print(f\"   Epochs: {EPOCHS}\")\n",
    "print(f\"   Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"   Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"   Optimizer: Adam\")\n",
    "print(f\"\\nüìà Final Results:\")\n",
    "print(f\"   Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"   Training Accuracy: {history['train_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"   Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"   Validation Accuracy: {history['val_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"   Best Validation Accuracy: {best_val_acc*100:.2f}% (Epoch {best_epoch})\")\n",
    "print(f\"\\n{'‚úì' if best_val_acc > 0.8 else '‚úó'} {'Model meets' if best_val_acc > 0.8 else 'Below'} 80% accuracy requirement\")\n",
    "print(f\"\\nüíæ Model saved to: {model_save_path}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
