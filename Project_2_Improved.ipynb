{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a94341",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64b8f620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb238dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f25ffd",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e54f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transforms\n",
    "# ImageNet normalization statistics\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# Training transforms with augmentation\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Test transforms (no augmentation for evaluation)\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7571b272",
   "metadata": {},
   "source": [
    "## 3. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11941f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetectionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-task learning model for object detection.\n",
    "    \n",
    "    Architecture:\n",
    "    - Backbone: ResNet50 (pretrained on ImageNet)\n",
    "    - Classification Head: Predicts cow stall numbers (61 classes)\n",
    "    - Regression Head: Predicts bounding box coordinates (4 values)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=61, num_bbox_coords=4):\n",
    "        super(ObjectDetectionModel, self).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50\n",
    "        self.backbone = models.resnet50(pretrained=True)\n",
    "        \n",
    "        # Get the number of input features for the FC layer\n",
    "        num_features = self.backbone.fc.in_features\n",
    "        \n",
    "        # Replace FC layer with identity to get feature maps\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        # Flatten layer\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "        \n",
    "        # Bounding box regression head\n",
    "        self.bbox_regressor = nn.Linear(num_features, num_bbox_coords)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features from backbone\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Flatten features\n",
    "        features = self.flatten(features)\n",
    "        \n",
    "        # Classification and bounding box predictions\n",
    "        class_logits = self.classifier(features)\n",
    "        bbox_coords = self.bbox_regressor(features)\n",
    "        \n",
    "        return class_logits, bbox_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d13e8cc",
   "metadata": {},
   "source": [
    "## 4. Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a5afc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CowStallDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for cow stall detection.\n",
    "    \n",
    "    Loads images and their corresponding:\n",
    "    - Stall number labels\n",
    "    - Bounding box coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: Pandas DataFrame with image paths and annotations\n",
    "            image_dir: Directory containing images\n",
    "            transform: Torchvision transforms to apply\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # Read image\n",
    "            image_filename = self.dataframe.iloc[idx, 0]\n",
    "            image_path = os.path.join(self.image_dir, image_filename)\n",
    "            \n",
    "            image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "            \n",
    "            # Resize image\n",
    "            image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "            \n",
    "            # Convert BGR to RGB\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "            \n",
    "            # Normalize to [0, 1]\n",
    "            image /= 255.0\n",
    "            \n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            # Get label (stall number)\n",
    "            label = torch.tensor(int(self.dataframe.iloc[idx, 5]), dtype=torch.long)\n",
    "            \n",
    "            # Get bounding box coordinates\n",
    "            bbox_columns = ['box_position_1', 'box_position_2', 'box_position_3', 'box_position_4']\n",
    "            bbox = self.dataframe.loc[idx, bbox_columns].values.astype(np.float32)\n",
    "            \n",
    "            # Convert (x, y, width, height) to (x1, y1, x2, y2)\n",
    "            bbox[2] = bbox[0] + bbox[2]  # x2 = x1 + width\n",
    "            bbox[3] = bbox[1] + bbox[3]  # y2 = y1 + height\n",
    "            \n",
    "            bbox = torch.as_tensor(bbox, dtype=torch.float32)\n",
    "            \n",
    "            return image, label, bbox\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading sample {idx}: {str(e)}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7e4c5",
   "metadata": {},
   "source": [
    "## 5. Data Loading (Update paths for your environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "263edb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  train_csv_path: /content/drive/MyDrive/New folder/Stall_num_images/Train.csv\n",
      "  test_csv_path: /content/drive/MyDrive/New folder/Stall_num_images/Test.csv\n",
      "  image_dir: /content/drive/MyDrive/Stall_num_images\n",
      "  batch_size: 4\n",
      "  num_workers: 0\n",
      "  epochs: 100\n",
      "  learning_rate: 0.0001\n",
      "  weight_decay: 0.0001\n",
      "  num_classes: 61\n"
     ]
    }
   ],
   "source": [
    "# Configuration - Update these paths for your environment\n",
    "CONFIG = {\n",
    "    'train_csv_path': \"/content/drive/MyDrive/New folder/Stall_num_images/Train.csv\",\n",
    "    'test_csv_path': \"/content/drive/MyDrive/New folder/Stall_num_images/Test.csv\",\n",
    "    'image_dir': \"/content/drive/MyDrive/Stall_num_images\",\n",
    "    'batch_size': 4,\n",
    "    'num_workers': 0,\n",
    "    'epochs': 100,\n",
    "    'learning_rate': 0.0001,\n",
    "    'weight_decay': 0.0001,\n",
    "    'num_classes': 61\n",
    "}\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98a3849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/New folder/Stall_num_images/Train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4055175603.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading datasets...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_csv_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_csv_path'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/New folder/Stall_num_images/Train.csv'"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"Loading datasets...\")\n",
    "df_train = pd.read_csv(CONFIG['train_csv_path']).fillna(0)\n",
    "df_test = pd.read_csv(CONFIG['test_csv_path']).fillna(0)\n",
    "\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Test samples: {len(df_test)}\")\n",
    "print(f\"\\nDataFrame columns: {df_train.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CowStallDataset(\n",
    "    df_train,\n",
    "    CONFIG['image_dir'],\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = CowStallDataset(\n",
    "    df_test,\n",
    "    CONFIG['image_dir'],\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c76d5",
   "metadata": {},
   "source": [
    "## 6. Model Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ObjectDetectionModel(\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    num_bbox_coords=4\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model moved to {device}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc7f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "criterion_classification = nn.CrossEntropyLoss()\n",
    "criterion_bbox = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(\n",
    "    trainable_params,\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=30,\n",
    "    gamma=0.1\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Scheduler: StepLR (step_size=30, gamma=0.1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a745c212",
   "metadata": {},
   "source": [
    "## 7. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62cf06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'train_accuracy': [],\n",
    "    'val_loss': [],\n",
    "    'val_accuracy': []\n",
    "}\n",
    "\n",
    "# Hyperparameters\n",
    "BBOX_LOSS_WEIGHT = 0.01  # Weight for bounding box loss\n",
    "EPOCHS = CONFIG['epochs']\n",
    "\n",
    "print(f\"Starting training for {EPOCHS} epochs...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26200963",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    # ==================== Training ====================\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels, bboxes) in enumerate(train_loader):\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        bboxes = bboxes.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        class_logits, bbox_predictions = model(images)\n",
    "        \n",
    "        # Calculate losses\n",
    "        loss_cls = criterion_classification(class_logits, labels)\n",
    "        loss_bbox = torch.sqrt(criterion_bbox(bbox_predictions, bboxes)) * BBOX_LOSS_WEIGHT\n",
    "        loss_total = loss_cls + loss_bbox\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss += loss_total.item()\n",
    "        predictions = torch.argmax(class_logits, dim=1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        train_total += labels.size(0)\n",
    "    \n",
    "    # Calculate training metrics\n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = train_correct / train_total\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_accuracy'].append(train_accuracy)\n",
    "    \n",
    "    # ==================== Validation ====================\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels, bboxes in test_loader:\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            bboxes = bboxes.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            class_logits, bbox_predictions = model(images)\n",
    "            \n",
    "            # Calculate losses\n",
    "            loss_cls = criterion_classification(class_logits, labels)\n",
    "            loss_bbox = torch.sqrt(criterion_bbox(bbox_predictions, bboxes)) * BBOX_LOSS_WEIGHT\n",
    "            loss_total = loss_cls + loss_bbox\n",
    "            \n",
    "            # Update metrics\n",
    "            val_loss += loss_total.item()\n",
    "            predictions = torch.argmax(class_logits, dim=1)\n",
    "            val_correct += (predictions == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    val_loss /= len(test_loader)\n",
    "    val_accuracy = val_correct / val_total\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_accuracy'].append(val_accuracy)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch {epoch + 1:3d}/{EPOCHS} | \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy*100:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f21476",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Final Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"Final Training Accuracy: {history['train_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"Final Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {history['val_accuracy'][-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5a9224",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea89ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', linewidth=2)\n",
    "axes[0].plot(history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(history['train_accuracy'], label='Train Accuracy', linewidth=2)\n",
    "axes[1].plot(history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best validation accuracy\n",
    "best_epoch = np.argmax(history['val_accuracy']) + 1\n",
    "best_val_acc = np.max(history['val_accuracy'])\n",
    "\n",
    "print(f\"\\nBest Validation Accuracy: {best_val_acc*100:.2f}% (Epoch {best_epoch})\")\n",
    "print(f\"✓ Model exceeds 80% accuracy requirement\" if best_val_acc > 0.8 else \"✗ Below 80% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efbfdb4",
   "metadata": {},
   "source": [
    "## 9. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "model_save_path = os.path.join(CONFIG['image_dir'], 'object_detection_model.pt')\n",
    "\n",
    "checkpoint = {\n",
    "    'epoch': EPOCHS,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'scheduler_state_dict': scheduler.state_dict(),\n",
    "    'train_loss': history['train_loss'][-1],\n",
    "    'val_loss': history['val_loss'][-1],\n",
    "    'val_accuracy': history['val_accuracy'][-1],\n",
    "    'config': CONFIG\n",
    "}\n",
    "\n",
    "try:\n",
    "    torch.save(checkpoint, model_save_path)\n",
    "    print(f\"Model saved successfully to: {model_save_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1918ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model function for future use\n",
    "def load_model(checkpoint_path, device):\n",
    "    \"\"\"\n",
    "    Load model from checkpoint.\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to saved checkpoint\n",
    "        device: Device to load model on\n",
    "    \n",
    "    Returns:\n",
    "        Loaded model and checkpoint information\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    model = ObjectDetectionModel(\n",
    "        num_classes=checkpoint['config']['num_classes'],\n",
    "        num_bbox_coords=4\n",
    "    ).to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "print(\"Model loading function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cdf4c8",
   "metadata": {},
   "source": [
    "## 10. Summary and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nDataset: Cow Stall Number Detection\")\n",
    "print(f\"  Training samples: {len(df_train)}\")\n",
    "print(f\"  Test samples: {len(df_test)}\")\n",
    "print(f\"\\nModel Architecture: ObjectDetectionModel\")\n",
    "print(f\"  Backbone: ResNet50 (pretrained)\")\n",
    "print(f\"  Classification classes: {CONFIG['num_classes']}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  Optimizer: Adam\")\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  Training Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Training Accuracy: {history['train_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  Validation Loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Validation Accuracy: {history['val_accuracy'][-1]*100:.2f}%\")\n",
    "print(f\"  Best Validation Accuracy: {best_val_acc*100:.2f}% (Epoch {best_epoch})\")\n",
    "print(f\"\\n✓ Model meets 80% accuracy requirement\" if best_val_acc > 0.8 else \"\\n✗ Below 80% accuracy\")\n",
    "print(f\"\\nModel saved to: {model_save_path}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
